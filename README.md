# ğŸ“„ DocMentorAI

**DocMentorAI** is a full-stack AI-powered web application that allows users to upload PDF documents and interact with them via chat. Using Retrieval-Augmented Generation (RAG), it processes the document, extracts key information, embeds it into a vector store, and enables natural language queries for intelligent Q&A over the document content.

---

## ğŸš€ Features

- ğŸ§  AI-powered chat over PDFs using Google Gemini
- ğŸ“„ Upload and process documents (PDF)
- ğŸ“Œ Chunking and semantic embedding of document content
- ğŸ” Fast retrieval with Qdrant vector store
- ğŸ› ï¸ BullMQ-powered background job queue for processing
- ğŸ“Š Real-time progress updates during embedding
- ğŸ” Clerk authentication (for user management)

---

## ğŸ§± Tech Stack

| Layer        | Technology                           |
|--------------|--------------------------------------|
| Frontend     | Next.js, Tailwind CSS                |
| Backend      | Node.js, Express.js                  |
| Auth         | Clerk                                |
| AI & LLM     | LangChain, Google Gemini / OpenAI    |
| Embeddings   | CustomNebius / OpenAI                |
| Vector DB    | Qdrant                               |
| Background   | BullMQ, Redis                        |
| File Uploads | Multer                               |

---

## ğŸ“ Project Structure

```
DocMentorAI/
â”œâ”€â”€ client/                        # Next.js frontend  
â”œâ”€â”€ server/                        # Express backend  
â”‚   â”œâ”€â”€ index.js                   # Main server file  
â”‚   â”œâ”€â”€ worker.js                  # BullMQ job worker  
â”‚   â””â”€â”€ CustomNebiusEmbeddings.js  # Custom embedding handler  
â”œâ”€â”€ docker-compose.yml             # Docker orchestration file  
â”œâ”€â”€ .gitignore                     # Git ignored files config  
â””â”€â”€ README.md                      # Project documentation
```


## ğŸ§ª How It Works
- User uploads a PDF

- File is processed by a BullMQ background worker

- PDF is split into chunks and converted to vector embeddings

- Embeddings are stored in Qdrant vector DB

- User chats with the document â€” relevant chunks are retrieved and passed to LLM for response
